{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_descriptor(descriptors, degree):\n",
    "    \"\"\"this function truncates an unshifted fourier descriptor array\n",
    "    and returns one also unshifted\"\"\"\n",
    "    if degree == -1:\n",
    "        return descriptors\n",
    "    descriptors = np.fft.fftshift(descriptors)\n",
    "    center_index = len(descriptors) // 2\n",
    "    descriptors = descriptors[\n",
    "        int(np.ceil(center_index-degree/2)):int(np.ceil(center_index+degree/2))]\n",
    "    descriptors = np.fft.ifftshift(descriptors)\n",
    "    return descriptors\n",
    "\n",
    "def reconstruct(descriptors, degree):\n",
    "    \"\"\" reconstruct(descriptors, degree) attempts to reconstruct the image\n",
    "    using the first [degree] descriptors of descriptors\"\"\"\n",
    "    # truncate the long list of descriptors to certain length\n",
    "    descriptor_in_use = truncate_descriptor(descriptors, degree)\n",
    "    contour_reconstruct = np.fft.ifft(descriptor_in_use)\n",
    "    contour_reconstruct = np.array(\n",
    "        [contour_reconstruct.real, contour_reconstruct.imag])\n",
    "    contour_reconstruct = np.transpose(contour_reconstruct)\n",
    "    contour_reconstruct = np.expand_dims(contour_reconstruct, axis=1)\n",
    "    # make positive\n",
    "    if contour_reconstruct.min() < 0:\n",
    "        contour_reconstruct -= contour_reconstruct.min()\n",
    "    # normalization\n",
    "    contour_reconstruct *= 300 / contour_reconstruct.max()\n",
    "    # type cast to int32\n",
    "    contour_reconstruct = contour_reconstruct.astype(np.int32, copy=False)\n",
    "    black = np.zeros((400, 400), np.uint8)\n",
    "    # draw and visualize\n",
    "    cv2.drawContours(black, contour_reconstruct, -1, 255, thickness=2)\n",
    "    cv2.imshow(\"black\", black)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "    return descriptor_in_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip(cnts, hierarchy, mask):\n",
    "    cnts_new = np.empty(len(mask), dtype=object)\n",
    "    for i in range(len(mask)):\n",
    "        need_flip = False\n",
    "        index = hierarchy[0, mask[i], 3]\n",
    "        while index != -1:\n",
    "            index = hierarchy[0, index, 3]\n",
    "            need_flip = not need_flip\n",
    "        if need_flip:\n",
    "            cnts_new[i] = np.flip(cnts[mask[i]], 0)\n",
    "        else:\n",
    "            cnts_new[i] = cnts[mask[i]]\n",
    "    return cnts_new\n",
    "\n",
    "def contour(img, mode='c'):\n",
    "    imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    if mode == 'c':\n",
    "        ret, thresh = cv2.threshold(imgray, 127, 255, 0)\n",
    "    else:\n",
    "        thresh = cv2.adaptiveThreshold(imgray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 81, -5)\n",
    "    _, cnts, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    mask = range(len(cnts))\n",
    "    if mode == 'q':\n",
    "        threshold = [80, 400]\n",
    "        mask = np.where(np.array([threshold[0]<len(n)<threshold[1] for n in cnts]) > 0)[0]\n",
    "#     outer: counter-clockwise, inner: clockwise, need to flip to align to counter-clockwise\n",
    "    print('Contour size:', np.asarray(cnts).shape)\n",
    "    cnts = flip(cnts, hierarchy, mask)\n",
    "    return cnts\n",
    "\n",
    "def fourier_descriptor(cnts):\n",
    "    fd = []\n",
    "    for i in cnts:\n",
    "        contour_array = i[:, 0, :]\n",
    "        contour_complex = np.empty(contour_array.shape[:-1], dtype=complex)\n",
    "        contour_complex.real = contour_array[:, 0]\n",
    "        contour_complex.imag = contour_array[:, 1]\n",
    "        fourier_result = np.fft.fft(contour_complex)\n",
    "        fd.append(fourier_result)\n",
    "    return fd\n",
    "\n",
    "def translation(fd):\n",
    "    t = np.array([fd[0].real, fd[0].imag])\n",
    "    fd[0] = 0\n",
    "    return fd, t\n",
    "\n",
    "def scaling(fd):\n",
    "    s = np.linalg.norm(fd)\n",
    "    fd /= s\n",
    "    return fd, s\n",
    "\n",
    "def invarient_fd(fd, shorter):\n",
    "    fd_new = truncate_descriptor(fd, shorter)\n",
    "    fd_new, t = translation(fd_new)\n",
    "    fd_new, s = scaling(fd_new)\n",
    "    c = np.fft.ifft(fd_new)\n",
    "    return fd_new, c, t, s\n",
    "\n",
    "def geometry(img, cnts):\n",
    "    v = []\n",
    "    center = np.array([img.shape[0]/2, img.shape[1]/2])\n",
    "    for cnt in cnts:\n",
    "        local = np.zeros(2)\n",
    "        for pair in cnt:\n",
    "            local += pair[0]\n",
    "        local /= len(cnt)\n",
    "        v.append(local-center)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(IMG_Q, img_C):\n",
    "    img_Q = cv2.imread(IMG_Q['IMG'])\n",
    "    img_C = cv2.imread(IMG_C['IMG'])\n",
    "    cnts_Q = contour(img_Q, IMG_Q['mode'])\n",
    "    cnts_C = contour(img_C, IMG_C['mode'])\n",
    "#     seems not invarient to index-shift \n",
    "#     cnts_Q[0] = np.roll(cnts_Q[0], 50, 0)\n",
    "    v_C = geometry(img_C, cnts_C)\n",
    "    fd_Q = fourier_descriptor(cnts_Q)\n",
    "    fd_C = fourier_descriptor(cnts_C)\n",
    "    shape = np.array([len(fd_Q), len(fd_C)])\n",
    "    correlate_QC = np.zeros(shape)\n",
    "    s_QC = np.zeros(shape)\n",
    "    t_QC = np.zeros(np.append(shape, 2))\n",
    "    for j in range(shape[0]):\n",
    "        for k in range(shape[1]):\n",
    "#             pick the first several most important points\n",
    "            shorter = min(len(fd_Q[j]), len(fd_C[k]))\n",
    "            fd_Q_j, c_Q, t_Q, s_Q = invarient_fd(fd_Q[j], shorter)\n",
    "            fd_C_k, c_C, t_C, s_C = invarient_fd(fd_C[k], shorter)\n",
    "            s_QC[j, k] = s_Q / s_C\n",
    "            t_QC[j, k] = t_Q - t_C\n",
    "#             if we want to neglect index-shift, we need to roll the original contour and pick the same length fd\n",
    "            correlate = np.abs(np.correlate(c_Q, c_C))*shorter\n",
    "#             print(correlate)\n",
    "            correlate = 2 - 2 * correlate\n",
    "            correlate_QC[j, k] = correlate\n",
    "#     need element-wise threshold for each prototype contour\n",
    "    M = np.where(correlate_QC < 0.2)\n",
    "    fit = []\n",
    "    s_cut = 0.8\n",
    "    d_cut = 0.7\n",
    "    for i in range(len(M[0])):\n",
    "        j = M[0][i]\n",
    "        k = M[1][i]\n",
    "        v_jk = s_QC[j, k] * v_C[k] + t_QC[j, k]\n",
    "        pair = [j]\n",
    "        for i_ in range(len(M[0])):\n",
    "            j_ = M[0][i_]\n",
    "            k_ = M[1][i_]\n",
    "            if k_ == k or j_ == j:\n",
    "                continue\n",
    "#             some problem in scaling and translation\n",
    "            s_similar = s_QC[j_, k_] / s_QC[j, k]\n",
    "            v_j_k_ = s_QC[j_, k_] * v_C[k_] + t_QC[j_, k_]\n",
    "            d_similar = v_j_k_ / v_jk\n",
    "            if s_cut<s_similar<1/s_cut and d_cut<d_similar.min() and d_similar.max()<1/d_cut:\n",
    "                pair.append(j_)\n",
    "#                 print('-'*80)\n",
    "#                 print(j, k)\n",
    "#                 print(j_, k_)\n",
    "#                 print('s_similar:', s_similar)\n",
    "#                 print('d_similar:', d_similar)\n",
    "        if len(pair) >= shape[1]:\n",
    "            fit.append(pair)\n",
    "#             print('pair:', pair)\n",
    "    if IMG_Q['draw']:\n",
    "        img = cv2.drawContours(img_Q ,cnts_Q, -1, (0,255,255), 2)\n",
    "        for i in M[0]:\n",
    "            img = cv2.drawContours(img ,cnts_Q, i, (0,0,255), 2)\n",
    "        for pair in fit:\n",
    "            for i in pair:\n",
    "                img = cv2.drawContours(img ,cnts_Q, i, (0,255,0), 2)\n",
    "        img = cv2.resize(img, (int(img.shape[1]*11/16), int(img.shape[0]*11/16)))\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey()\n",
    "        cv2.destroyAllWindows()\n",
    "    if IMG_C['draw']:\n",
    "        img = cv2.drawContours(img_C ,cnts_C, -1, (0,255,255), 2)\n",
    "        img = cv2.resize(img, (int(img.shape[1]*11/16), int(img.shape[0]*11/16)))\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey()\n",
    "        cv2.destroyAllWindows()\n",
    "    return correlate_QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contour size: (5154,)\n",
      "Contour size: (2,)\n"
     ]
    }
   ],
   "source": [
    "# Query image + Contour image\n",
    "IMG_Q = {'IMG':'fd_image/traffic5.jpg', 'mode':'q', 'draw':True}\n",
    "IMG_C = {'IMG':'fd_image/sign1.jpg', 'mode':'c', 'draw':False}\n",
    "c = correlation(IMG_Q, IMG_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color: 81, -5\n",
    "# threshold: 100, 500\n",
    "traffic3: 9, 10 (0.2, 0.6, 0.8)\n",
    "traffic4: 5, 6 (0.2, 0.7, 0.7)\n",
    "-------------------\n",
    "# threshold: 80, 400\n",
    "traffic5: 30, 31 (0.2, 0.8, 0.7)\n",
    "-------------------\n",
    "# threshold: 300, 1200\n",
    "traffic6: 12, 13 (0.3, -, -)\n",
    "--------------------------------------\n",
    "# color: 41, 5\n",
    "# threshold: 100, 500\n",
    "traffic7: (0.2, 0.8, 0.7, -2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remain to be done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. how to solve the situation when c1 and c2 have different length\n",
    "2. how to align the center using scaling and translation\n",
    "3. how to extract the contour precisely and robustly\n",
    "4. how to define the lower and upper bound of contour\n",
    "5. how to do correlation with different step length\n",
    "6. how to tune the similarity of different j and k\n",
    "7. how to make it index-shift invariant\n",
    "8. how to match the affine image\n",
    "9. more efficient cascaded matching scheme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
